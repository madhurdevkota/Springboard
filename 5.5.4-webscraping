Windows PowerShell
Copyright (C) Microsoft Corporation. All rights reserved.

Try the new cross-platform PowerShell https://aka.ms/pscore6

PS C:\Users\madhur> cd c:\
PS C:\> python-projects\machine-learning\Scripts\activate
(machine-learning) PS C:\> scrapy startproject tutorial
New Scrapy project 'tutorial', using template directory 'c:\\python-projects\\machine-learning\\lib\\site-packages\\scrapy\\templates\\project', created in:
    C:\tutorial

You can start your first spider with:
    cd tutorial
    scrapy genspider example example.com
(machine-learning) PS C:\> scrapy crawl quotes
Scrapy 1.3.3 - no active project

Unknown command: crawl

Use "scrapy" to see available commands
(machine-learning) PS C:\> cd .\tutorial\
(machine-learning) PS C:\tutorial> scrapy crawl quotes
2021-07-13 21:28:41 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: tutorial)
2021-07-13 21:28:41 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'tutorial', 'NEWSPIDER_MODULE': 'tutorial.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['tutorial.spiders']}
2021-07-13 21:28:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2021-07-13 21:28:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-07-13 21:28:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-07-13 21:28:41 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2021-07-13 21:28:41 [scrapy.core.engine] INFO: Spider opened
2021-07-13 21:28:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-07-13 21:28:41 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2021-07-13 21:28:41 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://quotes.toscrape.com/robots.txt> (referer: None)
2021-07-13 21:28:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/1/> (referer: None)
2021-07-13 21:28:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/2/> (referer: None)
2021-07-13 21:28:42 [quotes] DEBUG: Saved file quotes-1.html
2021-07-13 21:28:42 [quotes] DEBUG: Saved file quotes-2.html
2021-07-13 21:28:42 [scrapy.core.engine] INFO: Closing spider (finished)
2021-07-13 21:28:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 675,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 5642,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 7, 14, 3, 28, 42, 65477),
 'log_count/DEBUG': 6,
 'log_count/INFO': 7,
 'response_received_count': 3,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2021, 7, 14, 3, 28, 41, 650927)}
2021-07-13 21:28:42 [scrapy.core.engine] INFO: Spider closed (finished)
(machine-learning) PS C:\tutorial> scrapy shell 'http://quotes.toscrape.com/page/1/'
2021-07-13 21:28:56 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: tutorial)
2021-07-13 21:28:56 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'tutorial', 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter', 'LOGSTATS_INTERVAL': 0, 'NEWSPIDER_MODULE': 'tutorial.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['tutorial.spiders']}
2021-07-13 21:28:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole']
2021-07-13 21:28:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-07-13 21:28:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-07-13 21:28:57 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2021-07-13 21:28:57 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2021-07-13 21:28:57 [scrapy.core.engine] INFO: Spider opened
2021-07-13 21:28:57 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://quotes.toscrape.com/robots.txt> (referer: None)
2021-07-13 21:28:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/1/> (referer: None)
2021-07-13 21:28:57 [asyncio] DEBUG: Using selector: SelectSelector
[s] Available Scrapy objects:
[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)
[s]   crawler    <scrapy.crawler.Crawler object at 0x0000023D9457AC18>
[s]   item       {}
[s]   request    <GET http://quotes.toscrape.com/page/1/>
[s]   response   <200 http://quotes.toscrape.com/page/1/>
[s]   settings   <scrapy.settings.Settings object at 0x0000023D9457A978>
[s]   spider     <DefaultSpider 'default' at 0x23d947faef0>
[s] Useful shortcuts:
[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)
[s]   fetch(req)                  Fetch a scrapy.Request and update local objects
[s]   shelp()           Shell help (print this help)
[s]   view(response)    View response in a browser
2021-07-13 21:28:57 [asyncio] DEBUG: Using selector: SelectSelector
In [1]: response = load_response('http://quotes.toscrape.com/page/1/', 'quotes1.html')
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
<ipython-input-1-aaf170e9b255> in <module>
----> 1 response = load_response('http://quotes.toscrape.com/page/1/', 'quotes1.html')

NameError: name 'load_response' is not defined

In [2]: scrapy shell 'http://quotes.toscrape.com'
  File "<ipython-input-2-0d6f9b6b5eb2>", line 1
    scrapy shell 'http://quotes.toscrape.com'
               ^
SyntaxError: invalid syntax


In [3]: quote = response.css("div.quote")[0]

In [4]: xit
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
<ipython-input-4-bfb9c13ee2d2> in <module>
----> 1 xit

NameError: name 'xit' is not defined

In [5]: exit

(machine-learning) PS C:\tutorial> scrapy shell 'http://quotes.toscrape.com/page/1/'
2021-07-13 21:30:15 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: tutorial)
2021-07-13 21:30:15 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'tutorial', 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter', 'LOGSTATS_INTERVAL': 0, 'NEWSPIDER_MODULE': 'tutorial.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['tutorial.spiders']}
2021-07-13 21:30:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole']
2021-07-13 21:30:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-07-13 21:30:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-07-13 21:30:15 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2021-07-13 21:30:15 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2021-07-13 21:30:15 [scrapy.core.engine] INFO: Spider opened
2021-07-13 21:30:15 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://quotes.toscrape.com/robots.txt> (referer: None)
2021-07-13 21:30:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/1/> (referer: None)
2021-07-13 21:30:16 [asyncio] DEBUG: Using selector: SelectSelector
[s] Available Scrapy objects:
[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)
[s]   crawler    <scrapy.crawler.Crawler object at 0x00000182F1EFAC50>
[s]   item       {}
[s]   request    <GET http://quotes.toscrape.com/page/1/>
[s]   response   <200 http://quotes.toscrape.com/page/1/>
[s]   settings   <scrapy.settings.Settings object at 0x00000182F1EFA9B0>
[s]   spider     <DefaultSpider 'default' at 0x182f218a048>
[s] Useful shortcuts:
[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)
[s]   fetch(req)                  Fetch a scrapy.Request and update local objects
[s]   shelp()           Shell help (print this help)
[s]   view(response)    View response in a browser
2021-07-13 21:30:16 [asyncio] DEBUG: Using selector: SelectSelector
In [1]: quote = response.css("div.quote")[0]

In [2]: text = quote.css("span.text::text").get()

In [3]: text
Out[3]: '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'

In [4]: tags = quote.css("div.tags a.tag::text").getall()

In [5]: tags
Out[5]: ['change', 'deep-thoughts', 'thinking', 'world']

In [6]: for quote in response.css("div.quote"):
   ...:
   ...:     text = quote.css("span.text::text").get()
   ...:
   ...:     author = quote.css("small.author::text").get()
   ...:
   ...:     tags = quote.css("div.tags a.tag::text").getall()
   ...:
   ...:     print(dict(text=text, author=author, tags=tags))
   ...:
{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'tags': ['change', 'deep-thoughts', 'thinking', 'world']}
{'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'tags': ['abilities', 'choices']}
{'text': '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'author': 'Albert Einstein', 'tags': ['inspirational', 'life', 'live', 'miracle', 'miracles']}
{'text': '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', 'author': 'Jane Austen', 'tags': ['aliteracy', 'books', 'classic', 'humor']}
{'text': "“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”", 'author': 'Marilyn Monroe', 'tags': ['be-yourself', 'inspirational']}
{'text': '“Try not to become a man of success. Rather become a man of value.”', 'author': 'Albert Einstein', 'tags': ['adulthood', 'success', 'value']}
{'text': '“It is better to be hated for what you are than to be loved for what you are not.”', 'author': 'André Gide', 'tags': ['life', 'love']}
{'text': "“I have not failed. I've just found 10,000 ways that won't work.”", 'author': 'Thomas A. Edison', 'tags': ['edison', 'failure', 'inspirational', 'paraphrased']}
{'text': "“A woman is like a tea bag; you never know how strong it is until it's in hot water.”", 'author': 'Eleanor Roosevelt', 'tags': ['misattributed-eleanor-roosevelt']}
{'text': '“A day without sunshine is like, you know, night.”', 'author': 'Steve Martin', 'tags': ['humor', 'obvious', 'simile']}

In [7]: scrapy crawl quotes -O quotes.json
  File "<ipython-input-7-95bbb31e65e7>", line 1
    scrapy crawl quotes -O quotes.json
               ^
SyntaxError: invalid syntax


In [8]: response.css('li.next a').get()
Out[8]: '<a href="/page/2/">Next <span aria-hidden="true">→</span></a>'

In [9]: exit()

(machine-learning) PS C:\tutorial> scrapy shell 'http://quotes.toscrape.com/page/1/'
2021-07-13 21:32:39 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: tutorial)
2021-07-13 21:32:39 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'tutorial', 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter', 'LOGSTATS_INTERVAL': 0, 'NEWSPIDER_MODULE': 'tutorial.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['tutorial.spiders']}
2021-07-13 21:32:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole']
2021-07-13 21:32:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-07-13 21:32:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-07-13 21:32:40 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2021-07-13 21:32:40 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2021-07-13 21:32:40 [scrapy.core.engine] INFO: Spider opened
2021-07-13 21:32:40 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://quotes.toscrape.com/robots.txt> (referer: None)
2021-07-13 21:32:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/1/> (referer: None)
2021-07-13 21:32:40 [asyncio] DEBUG: Using selector: SelectSelector
[s] Available Scrapy objects:
[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)
[s]   crawler    <scrapy.crawler.Crawler object at 0x000001E1E207AC50>
[s]   item       {}
[s]   request    <GET http://quotes.toscrape.com/page/1/>
[s]   response   <200 http://quotes.toscrape.com/page/1/>
[s]   settings   <scrapy.settings.Settings object at 0x000001E1E207A9B0>
[s]   spider     <DefaultSpider 'default' at 0x1e1e22faef0>
[s] Useful shortcuts:
[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)
[s]   fetch(req)                  Fetch a scrapy.Request and update local objects
[s]   shelp()           Shell help (print this help)
[s]   view(response)    View response in a browser
2021-07-13 21:32:40 [asyncio] DEBUG: Using selector: SelectSelector
In [1]: response.css('li.next a').get()
Out[1]: '<a href="/page/2/">Next <span aria-hidden="true">→</span></a>'

In [2]: response.css('li.next a::attr(href)').get()
Out[2]: '/page/2/'

In [3]: response.css('li.next a').attrib['href']
Out[3]: '/page/2/'

In [4]: import scrapy
   ...:
   ...:
   ...: class QuotesSpider(scrapy.Spider):
   ...:     name = "quotes"
   ...:     start_urls = [
   ...:         'http://quotes.toscrape.com/page/1/',
   ...:     ]
   ...:
   ...:     def parse(self, response):
   ...:         for quote in response.css('div.quote'):
   ...:             yield {
   ...:                 'text': quote.css('span.text::text').get(),
   ...:                 'author': quote.css('span small::text').get(),
   ...:                 'tags': quote.css('div.tags a.tag::text').getall(),
   ...:             }
   ...:
   ...:         next_page = response.css('li.next a::attr(href)').get()
   ...:         if next_page is not None:
   ...:             yield response.follow(next_page, callback=self.parse)
   ...:

In [5]:

In [5]: for href in response.css('ul.pager a::attr(href)'):
   ...:     yield response.follow(href, callback=self.parse)
  File "<ipython-input-5-06722c09ff0b>", line 2
    yield response.follow(href, callback=self.parse)
    ^
SyntaxError: 'yield' outside function


In [6]:

In [6]: import scrapy

In [7]: scrapy crawl quotes -O quotes.json
  File "<ipython-input-7-95bbb31e65e7>", line 1
    scrapy crawl quotes -O quotes.json
               ^
SyntaxError: invalid syntax


In [8]: anchors = response.css('ul.pager a')

In [9]: anchors = response.css('ul.pager a')

In [10]: yield from response.follow_all(anchors, callback=self.parse)
  File "<ipython-input-10-3032d46c9a3f>", line 1
    yield from response.follow_all(anchors, callback=self.parse)
                                                                ^
SyntaxError: 'yield' outside function


In [11]: import yield
  File "<ipython-input-11-6fcfbfd63108>", line 1
    import yield
               ^
SyntaxError: invalid syntax


In [12]: scrapy crawl quotes -O quotes-humor.json -a tag=humor
  File "<ipython-input-12-45d6aa33b120>", line 1
    scrapy crawl quotes -O quotes-humor.json -a tag=humor
               ^
SyntaxError: invalid syntax